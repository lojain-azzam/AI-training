{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55444744",
   "metadata": {},
   "source": [
    "## Optional Assignment: Advanced NumPy and PyTorch Operations with MNIST\n",
    "**Description:**\n",
    "\n",
    "This optional assignment is designed to enhance your skills in NumPy and PyTorch, focusing on tensor operations using the MNIST dataset. By completing this assignment, you'll gain hands-on experience with advanced tensor manipulations, data preprocessing, and visualization techniques commonly used in deep learning projects.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* Practice tensor operations in PyTorch\n",
    "* Explore data manipulation techniques with the MNIST dataset\n",
    "* Gain experience in converting between NumPy arrays and PyTorch tensors\n",
    "* Enhance your understanding of tensor shapes and dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081bb3e0",
   "metadata": {},
   "source": [
    "# Intro about PyTorch\n",
    "PyTorch is an open-source machine learning library for Python that is primarily used for building and training deep neural networks. It was developed by the AI research group at Facebook's AI Research lab (FAIR) and is now widely used in the machine learning and deep learning community.\n",
    "\n",
    "PyTorch is a powerful and flexible deep learning framework that has gained significant popularity in the machine learning community. Its dynamic computational graphs, ease of use, and strong support for research and production make it a compelling choice for a wide range of machine learning applications.\n",
    "* The MNIST (Modified National Institute of Standards and Technology) dataset is a widely-used dataset in the field of machine learning and computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0a043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random NumPy array:\n",
      "[[0.86005324 0.23327059 0.69339303 0.0806209 ]\n",
      " [0.71540044 0.21821474 0.4474634  0.98316759]\n",
      " [0.16283096 0.64292887 0.5344528  0.04662871]]\n",
      "\n",
      "Random PyTorch tensor:\n",
      "tensor([[0.0266, 0.9787, 0.8226, 0.9252],\n",
      "        [0.7773, 0.8750, 0.1310, 0.8453],\n",
      "        [0.4742, 0.8261, 0.5040, 0.0741]])\n"
     ]
    }
   ],
   "source": [
    "# NumPy and PyTorch Tensor Operations Assignment\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Create a random NumPy array\n",
    "np_random = np.random.rand(3, 4)\n",
    "print(\"Random NumPy array:\")\n",
    "print(np_random)\n",
    "\n",
    "# Create a random PyTorch tensor\n",
    "torch_random = torch.rand(3, 4)\n",
    "print(\"\\nRandom PyTorch tensor:\")\n",
    "print(torch_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ece368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped NumPy array:\n",
      "[[0.86005324 0.23327059 0.69339303 0.0806209  0.71540044 0.21821474]\n",
      " [0.4474634  0.98316759 0.16283096 0.64292887 0.5344528  0.04662871]]\n",
      "\n",
      "Reshaped PyTorch tensor:\n",
      "tensor([[0.0266, 0.9787, 0.8226, 0.9252, 0.7773, 0.8750],\n",
      "        [0.1310, 0.8453, 0.4742, 0.8261, 0.5040, 0.0741]])\n"
     ]
    }
   ],
   "source": [
    "#  Reshaping\n",
    "# Reshape NumPy array\n",
    "np_reshaped = np_random.reshape(2, 6)\n",
    "print(\"Reshaped NumPy array:\")\n",
    "print(np_reshaped)\n",
    "\n",
    "# Reshape PyTorch tensor\n",
    "torch_reshaped = torch_random.reshape(2, 6)\n",
    "print(\"\\nReshaped PyTorch tensor:\")\n",
    "print(torch_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df42006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array multiplication:\n",
      "[[1.72010648 0.46654119 1.38678607 0.1612418 ]\n",
      " [1.43080088 0.43642949 0.8949268  1.96633518]\n",
      " [0.32566192 1.28585775 1.06890559 0.09325742]]\n",
      "\n",
      "PyTorch tensor multiplication:\n",
      "tensor([[0.0533, 1.9574, 1.6453, 1.8504],\n",
      "        [1.5547, 1.7500, 0.2621, 1.6906],\n",
      "        [0.9484, 1.6521, 1.0081, 0.1482]])\n"
     ]
    }
   ],
   "source": [
    "# NumPy array multiplication\n",
    "np_mult = np.multiply(np_random, 2)\n",
    "print(\"NumPy array multiplication:\")\n",
    "print(np_mult)\n",
    "\n",
    "# PyTorch tensor multiplication\n",
    "torch_mult = torch.mul(torch_random, 2)\n",
    "print(\"\\nPyTorch tensor multiplication:\")\n",
    "print(torch_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db3ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuted NumPy array:\n",
      "[[0.86005324 0.71540044 0.16283096]\n",
      " [0.23327059 0.21821474 0.64292887]\n",
      " [0.69339303 0.4474634  0.5344528 ]\n",
      " [0.0806209  0.98316759 0.04662871]]\n",
      "\n",
      "Permuted PyTorch tensor:\n",
      "tensor([[0.0266, 0.7773, 0.4742],\n",
      "        [0.9787, 0.8750, 0.8261],\n",
      "        [0.8226, 0.1310, 0.5040],\n",
      "        [0.9252, 0.8453, 0.0741]])\n"
     ]
    }
   ],
   "source": [
    "#  Permute shape\n",
    "# Permute NumPy array\n",
    "np_permuted = np.transpose(np_random, (1, 0))\n",
    "print(\"Permuted NumPy array:\")\n",
    "print(np_permuted)\n",
    "\n",
    "# Permute PyTorch tensor\n",
    "torch_permuted = torch_random.permute(1, 0)\n",
    "print(\"\\nPermuted PyTorch tensor:\")\n",
    "print(torch_permuted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b70b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy to PyTorch:\n",
      "tensor([[0.8601, 0.2333, 0.6934, 0.0806],\n",
      "        [0.7154, 0.2182, 0.4475, 0.9832],\n",
      "        [0.1628, 0.6429, 0.5345, 0.0466]], dtype=torch.float64)\n",
      "\n",
      "PyTorch to NumPy:\n",
      "[[0.02663314 0.9787178  0.8226456  0.9251889 ]\n",
      " [0.7773302  0.87498504 0.13102645 0.84531766]\n",
      " [0.4742012  0.82605547 0.50402814 0.07410818]]\n"
     ]
    }
   ],
   "source": [
    "# Convert between NumPy and PyTorch\n",
    "# NumPy to PyTorch\n",
    "np_to_torch = torch.from_numpy(np_random)\n",
    "print(\"NumPy to PyTorch:\")\n",
    "print(np_to_torch)\n",
    "\n",
    "# PyTorch to NumPy\n",
    "torch_to_np = torch_random.numpy()\n",
    "print(\"\\nPyTorch to NumPy:\")\n",
    "print(torch_to_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafb6192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the batch: torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# NumPy and PyTorch Tensor Operations on MNIST Dataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a batch of MNIST images\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Shape of the batch:\", images.shape)\n",
    "\n",
    "# Concatenation\n",
    "# Concatenate along the batch dimension\n",
    "concat_images = torch.cat((images, images), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6fe92ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the batch: torch.Size([64, 1, 28, 28])\n",
      "Shape after concatenation: torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# NumPy and PyTorch Tensor Operations on MNIST Dataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a batch of MNIST images\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Shape of the batch:\", images.shape)\n",
    "\n",
    "# Concatenation\n",
    "# Concatenate along the batch dimension\n",
    "concat_images = torch.cat((images, images), dim=0)\n",
    "print(\"Shape after concatenation:\", concat_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be1280",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "* The `MNIST` dataset is a well-known dataset in the field of computer vision, consisting of 60,000 training images and 10,000 test images of handwritten digits (0-9).\n",
    "* The `\"batch\"` in the context of this code refers to a subset or a group of samples from the overall dataset that are processed together during training or evaluation of a machine learning model.\n",
    "* The `batch size` is set to `64`, meaning that eachbatch will contain 64 images.\n",
    "* The shape of the batch of images is printed, which is `torch.Size([64, 1, 28, 28])`. This indicates that the batch contains `64 images`, each with a `single channel (grayscale)` and dimensions of `28x28 pixels`.\n",
    "* The resulting concat_images tensor has a shape of `torch.Size([128, 1, 28, 28]),` as the batch size has been increased from `64 to 128.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f49bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after adding dimension: torch.Size([64, 1, 1, 28, 28])\n",
      "Shape after removing dimension: torch.Size([64, 1, 28, 28])\n",
      "Shape of flattened images: torch.Size([64, 784])\n",
      "Shape of first 10 images: torch.Size([10, 1, 28, 28])\n",
      "Shape of first image (all channels): torch.Size([1, 28, 28])\n",
      "Shape of center slice: torch.Size([64, 0, 14, 28])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (0, 14, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Center slice\u001b[39;00m\n\u001b[1;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(center_slice[\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCenter Slice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:3358\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3339\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3357\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3358\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[1;32m   3359\u001b[0m         X,\n\u001b[1;32m   3360\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[1;32m   3361\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   3362\u001b[0m         aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[1;32m   3363\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[1;32m   3364\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   3365\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[1;32m   3366\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[1;32m   3367\u001b[0m         origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[1;32m   3368\u001b[0m         extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[1;32m   3369\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   3370\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   3371\u001b[0m         filterrad\u001b[38;5;241m=\u001b[39mfilterrad,\n\u001b[1;32m   3372\u001b[0m         resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   3373\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   3374\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3375\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3376\u001b[0m     )\n\u001b[1;32m   3377\u001b[0m     sci(__ret)\n\u001b[1;32m   3378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_axes.py:5759\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5759\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[1;32m   5760\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5762\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_image_array(A)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/image.py:693\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (0, 14, 28) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: Add and remove dimensions\n",
    "# TODO: Add a new dimension to the 'images' tensor\n",
    "expanded_images = images.unsqueeze(1)\n",
    "print(\"Shape after adding dimension:\", expanded_images.shape)\n",
    "\n",
    "\n",
    "# TODO: Remove the added dimension from 'expanded_images'\n",
    "squeezed_images = expanded_images.squeeze(1)\n",
    "print(\"Shape after removing dimension:\", squeezed_images.shape)\n",
    "\n",
    "# Cell 5: Flatten tensors\n",
    "# TODO: Flatten the 'images' tensor to have shape (batch_size, -1)\n",
    "flattened_images = images.view(images.size(0), -1)\n",
    "print(\"Shape of flattened images:\", flattened_images.shape)\n",
    "\n",
    "# Cell 6: Slicing\n",
    "# TODO: Get the first 10 images from the 'images' tensor\n",
    "first_10_images = images[:10]\n",
    "print(\"Shape of first 10 images:\", first_10_images.shape)\n",
    "\n",
    "# TODO: Get all channels of the first image\n",
    "first_image_all_channels = images[0]\n",
    "print(\"Shape of first image (all channels):\", first_image_all_channels.shape)\n",
    "\n",
    "# TODO: Get a 14x14 slice from the center of each image\n",
    "center_slice = images[:, 7:21, 7:21]\n",
    "print(\"Shape of center slice:\", center_slice.shape)\n",
    "\n",
    "# Cell 7: Visualize original and manipulated images\n",
    "# TODO: Complete the visualization code\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Flattened and reshaped image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(flattened_images[0].view(28, 28), cmap='gray')\n",
    "plt.title(\"Flattened and Reshaped Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Center slice\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(center_slice[0], cmap='gray')\n",
    "plt.title(\"Center Slice\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 8: Convert between NumPy and PyTorch\n",
    "# TODO: Convert the PyTorch 'images' tensor to a NumPy array\n",
    "np_images = images.cpu().numpy()\n",
    "print(\"Shape of NumPy array:\", np_images.shape)\n",
    "\n",
    "# TODO: Convert the NumPy array back to a PyTorch tensor\n",
    "torch_images = torch.from_numpy(np_images)\n",
    "print(\"Shape of PyTorch tensor:\", torch_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc23dea",
   "metadata": {},
   "source": [
    "Note:\n",
    "- This code demonstrates various tensor manipulation operations in PyTorch, including adding and removing dimensions, flattening tensors, and slicing tensors.\n",
    "\n",
    "Adding and Removing Dimensions:\n",
    "- The code adds a new dimension to the 'images' tensor using the `unsqueeze()` method, creating a 4D tensor with shape (batch_size, 1, height, width).\n",
    "- It then removes the added dimension using the `squeeze()` method, returning the tensor back to its original 3D shape (batch_size, height, width).\n",
    "\n",
    "Flattening Tensors:\n",
    "- The code flattens the 'images' tensor using the `view()` method, converting the 3D tensor (batch_size, height, width) to a 2D tensor (batch_size, height * width).\n",
    "\n",
    "Slicing Tensors:\n",
    "- The code extracts the first 10 images from the 'images' tensor using slicing with the range `[:10]`.\n",
    "- It then extracts all the channels of the first image using `images[0]`.\n",
    "- Finally, it extracts a 14x14 center slice from each image using the range `[:, 7:21, 7:21]`.\n",
    "\n",
    "Visualization:\n",
    "- The code visualizes the original image, the flattened and reshaped image, and the center slice using Matplotlib's `imshow()` function.\n",
    "\n",
    "Converting between NumPy and PyTorch:\n",
    "- The code converts the PyTorch 'images' tensor to a NumPy array using the `cpu().numpy()` method.\n",
    "- It then converts the NumPy array back to a PyTorch tensor using `torch.from_numpy()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5711dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
