{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55444744",
   "metadata": {},
   "source": [
    "## Optional Assignment: Advanced NumPy and PyTorch Operations with MNIST\n",
    "**Description:**\n",
    "\n",
    "This optional assignment is designed to enhance your skills in NumPy and PyTorch, focusing on tensor operations using the MNIST dataset. By completing this assignment, you'll gain hands-on experience with advanced tensor manipulations, data preprocessing, and visualization techniques commonly used in deep learning projects.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* Practice tensor operations in PyTorch\n",
    "* Explore data manipulation techniques with the MNIST dataset\n",
    "* Gain experience in converting between NumPy arrays and PyTorch tensors\n",
    "* Enhance your understanding of tensor shapes and dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081bb3e0",
   "metadata": {},
   "source": [
    "# Intro about PyTorch\n",
    "PyTorch is an open-source machine learning library for Python that is primarily used for building and training deep neural networks. It was developed by the AI research group at Facebook's AI Research lab (FAIR) and is now widely used in the machine learning and deep learning community.\n",
    "\n",
    "PyTorch is a powerful and flexible deep learning framework that has gained significant popularity in the machine learning community. Its dynamic computational graphs, ease of use, and strong support for research and production make it a compelling choice for a wide range of machine learning applications.\n",
    "* The MNIST (Modified National Institute of Standards and Technology) dataset is a widely-used dataset in the field of machine learning and computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0a043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random NumPy array:\n",
      "[[0.37171562 0.04387089 0.18931101 0.52209766]\n",
      " [0.76461263 0.62944699 0.12433386 0.46762562]\n",
      " [0.1746179  0.89755662 0.28484194 0.74498981]]\n",
      "\n",
      "Random PyTorch tensor:\n",
      "tensor([[0.7600, 0.7793, 0.0824, 0.3593],\n",
      "        [0.5749, 0.2444, 0.8434, 0.6854],\n",
      "        [0.3369, 0.4355, 0.5861, 0.6489]])\n"
     ]
    }
   ],
   "source": [
    "# NumPy and PyTorch Tensor Operations Assignment\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Create a random NumPy array\n",
    "np_random = np.random.rand(3, 4)\n",
    "print(\"Random NumPy array:\")\n",
    "print(np_random)\n",
    "\n",
    "# Create a random PyTorch tensor\n",
    "torch_random = torch.rand(3, 4)\n",
    "print(\"\\nRandom PyTorch tensor:\")\n",
    "print(torch_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ece368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped NumPy array:\n",
      "[[0.37171562 0.04387089 0.18931101 0.52209766 0.76461263 0.62944699]\n",
      " [0.12433386 0.46762562 0.1746179  0.89755662 0.28484194 0.74498981]]\n",
      "\n",
      "Reshaped PyTorch tensor:\n",
      "tensor([[0.7600, 0.7793, 0.0824, 0.3593, 0.5749, 0.2444],\n",
      "        [0.8434, 0.6854, 0.3369, 0.4355, 0.5861, 0.6489]])\n"
     ]
    }
   ],
   "source": [
    "#  Reshaping\n",
    "# Reshape NumPy array\n",
    "np_reshaped = np_random.reshape(2, 6)\n",
    "print(\"Reshaped NumPy array:\")\n",
    "print(np_reshaped)\n",
    "\n",
    "# Reshape PyTorch tensor\n",
    "torch_reshaped = torch_random.reshape(2, 6)\n",
    "print(\"\\nReshaped PyTorch tensor:\")\n",
    "print(torch_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df42006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array multiplication:\n",
      "[[0.74343124 0.08774178 0.37862203 1.04419531]\n",
      " [1.52922525 1.25889398 0.24866772 0.93525123]\n",
      " [0.34923579 1.79511324 0.56968388 1.48997962]]\n",
      "\n",
      "PyTorch tensor multiplication:\n",
      "tensor([[1.5201, 1.5587, 0.1648, 0.7187],\n",
      "        [1.1498, 0.4888, 1.6868, 1.3707],\n",
      "        [0.6739, 0.8710, 1.1723, 1.2978]])\n"
     ]
    }
   ],
   "source": [
    "# NumPy array multiplication\n",
    "np_mult = np.multiply(np_random, 2)\n",
    "print(\"NumPy array multiplication:\")\n",
    "print(np_mult)\n",
    "\n",
    "# PyTorch tensor multiplication\n",
    "torch_mult = torch.mul(torch_random, 2)\n",
    "print(\"\\nPyTorch tensor multiplication:\")\n",
    "print(torch_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db3ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuted NumPy array:\n",
      "[[0.37171562 0.76461263 0.1746179 ]\n",
      " [0.04387089 0.62944699 0.89755662]\n",
      " [0.18931101 0.12433386 0.28484194]\n",
      " [0.52209766 0.46762562 0.74498981]]\n",
      "\n",
      "Permuted PyTorch tensor:\n",
      "tensor([[0.7600, 0.5749, 0.3369],\n",
      "        [0.7793, 0.2444, 0.4355],\n",
      "        [0.0824, 0.8434, 0.5861],\n",
      "        [0.3593, 0.6854, 0.6489]])\n"
     ]
    }
   ],
   "source": [
    "#  Permute shape\n",
    "# Permute NumPy array\n",
    "np_permuted = np.transpose(np_random, (1, 0))\n",
    "print(\"Permuted NumPy array:\")\n",
    "print(np_permuted)\n",
    "\n",
    "# Permute PyTorch tensor\n",
    "torch_permuted = torch_random.permute(1, 0)\n",
    "print(\"\\nPermuted PyTorch tensor:\")\n",
    "print(torch_permuted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b70b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy to PyTorch:\n",
      "tensor([[0.3717, 0.0439, 0.1893, 0.5221],\n",
      "        [0.7646, 0.6294, 0.1243, 0.4676],\n",
      "        [0.1746, 0.8976, 0.2848, 0.7450]], dtype=torch.float64)\n",
      "\n",
      "PyTorch to NumPy:\n",
      "[[0.7600362  0.7793435  0.08240658 0.3593309 ]\n",
      " [0.57487506 0.24438035 0.84340537 0.6853526 ]\n",
      " [0.3369345  0.43551874 0.5861282  0.6488763 ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert between NumPy and PyTorch\n",
    "# NumPy to PyTorch\n",
    "np_to_torch = torch.from_numpy(np_random)\n",
    "print(\"NumPy to PyTorch:\")\n",
    "print(np_to_torch)\n",
    "\n",
    "# PyTorch to NumPy\n",
    "torch_to_np = torch_random.numpy()\n",
    "print(\"\\nPyTorch to NumPy:\")\n",
    "print(torch_to_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafb6192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the batch: torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# NumPy and PyTorch Tensor Operations on MNIST Dataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a batch of MNIST images\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Shape of the batch:\", images.shape)\n",
    "\n",
    "# Concatenation\n",
    "# Concatenate along the batch dimension\n",
    "concat_images = torch.cat((images, images), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0064318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the batch: torch.Size([64, 1, 28, 28])\n",
      "Shape after concatenation: torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# NumPy and PyTorch Tensor Operations on MNIST Dataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a batch of MNIST images\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Shape of the batch:\", images.shape)\n",
    "\n",
    "# Concatenation\n",
    "# Concatenate along the batch dimension\n",
    "concat_images = torch.cat((images, images), dim=0)\n",
    "print(\"Shape after concatenation:\", concat_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a0d15",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "* The `MNIST` dataset is a well-known dataset in the field of computer vision, consisting of 60,000 training images and 10,000 test images of handwritten digits (0-9).\n",
    "* The `\"batch\"` in the context of this code refers to a subset or a group of samples from the overall dataset that are processed together during training or evaluation of a machine learning model.\n",
    "* The `batch size` is set to `64`, meaning that eachbatch will contain 64 images.\n",
    "* The shape of the batch of images is printed, which is `torch.Size([64, 1, 28, 28])`. This indicates that the batch contains `64 images`, each with a `single channel (grayscale)` and dimensions of `28x28 pixels`.\n",
    "* The resulting concat_images tensor has a shape of `torch.Size([128, 1, 28, 28]),` as the batch size has been increased from `64 to 128.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f49bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after adding dimension: torch.Size([64, 1, 1, 28, 28])\n",
      "Shape after removing dimension: torch.Size([64, 1, 28, 28])\n",
      "Shape of flattened images: torch.Size([64, 784])\n",
      "Shape of first 10 images: torch.Size([10, 1, 28, 28])\n",
      "Shape of first image (all channels): torch.Size([1, 28, 28])\n",
      "Shape of center slice: torch.Size([64, 1, 14, 14])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of NumPy array: (64, 1, 28, 28)\n",
      "Shape of PyTorch tensor: torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Add and remove dimensions\n",
    "# TODO: Add a new dimension to the 'images' tensor\n",
    "expanded_images = images.unsqueeze(1)\n",
    "print(\"Shape after adding dimension:\", expanded_images.shape)\n",
    "\n",
    "\n",
    "# TODO: Remove the added dimension from 'expanded_images'\n",
    "squeezed_images = expanded_images.squeeze(1)\n",
    "print(\"Shape after removing dimension:\", squeezed_images.shape)\n",
    "\n",
    "# Cell 5: Flatten tensors\n",
    "# TODO: Flatten the 'images' tensor to have shape (batch_size, -1)\n",
    "flattened_images = images.view(images.size(0), -1)\n",
    "print(\"Shape of flattened images:\", flattened_images.shape)\n",
    "\n",
    "# Cell 6: Slicing\n",
    "# TODO: Get the first 10 images from the 'images' tensor\n",
    "first_10_images = images[:10]\n",
    "print(\"Shape of first 10 images:\", first_10_images.shape)\n",
    "\n",
    "# TODO: Get all channels of the first image\n",
    "first_image_all_channels = images[0]\n",
    "print(\"Shape of first image (all channels):\", first_image_all_channels.shape)\n",
    "\n",
    "# TODO: Get a 14x14 slice from the center of each image\n",
    "center_slice = images[:,:,7:21, 7:21]\n",
    "print(\"Shape of center slice:\", center_slice.shape)\n",
    "\n",
    "# Cell 7: Visualize original and manipulated images\n",
    "# TODO: Complete the visualization code\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Flattened and reshaped image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(flattened_images[0].view(28, 28), cmap='gray')\n",
    "plt.title(\"Flattened and Reshaped Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Center slice\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(center_slice[0][0], cmap='gray')\n",
    "plt.title(\"Center Slice\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 8: Convert between NumPy and PyTorch\n",
    "# TODO: Convert the PyTorch 'images' tensor to a NumPy array\n",
    "np_images = images.cpu().numpy()\n",
    "print(\"Shape of NumPy array:\", np_images.shape)\n",
    "\n",
    "# TODO: Convert the NumPy array back to a PyTorch tensor\n",
    "torch_images = torch.from_numpy(np_images)\n",
    "print(\"Shape of PyTorch tensor:\", torch_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa12a6",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "\n",
    "In PyTorch, tensors representing images usually have a shape of `(batch_size, channels, height, width)`, where:\n",
    "\n",
    "1. batch_size is the number of images in the batch, `batch_size refers to the number of images that are processed together as a group`.\n",
    "2. channels is the number of color channels in the image `(1 for grayscale, 3 for RGB, etc.)`.\n",
    "3. height and width are the dimensions of the image.\n",
    "\n",
    "- This code demonstrates various tensor manipulation operations in PyTorch, including adding and removing dimensions, flattening tensors, and slicing tensors.\n",
    "\n",
    "Adding and Removing Dimensions:\n",
    "- The code adds a new dimension to the 'images' tensor using the `unsqueeze()` method, creating a 4D tensor with shape (batch_size, 1, height, width).\n",
    "- It then removes the added dimension using the `squeeze()` method, returning the tensor back to its original 3D shape (batch_size, height, width).\n",
    "\n",
    "Flattening Tensors:\n",
    "\n",
    "- The flattening process takes the 3D image tensors and reshapes them into 2D tensors, where each 2D tensor represents a single image. The height and width dimensions (28 x 28 = 784) are combined into a single dimension, resulting in a vector of length 784 for each image.\n",
    "- The code flattens the 'images' tensor using the `view()` method, converting the 3D tensor (batch_size, height, width) to a 2D tensor (batch_size, height * width).\n",
    "\n",
    "Slicing Tensors:\n",
    "- The code extracts the first 10 images from the 'images' tensor using slicing with the range `[:10]`.\n",
    "- It then extracts all the channels of the first image using `images[0]`.\n",
    "- Finally, it extracts a 14x14 center slice from each image using the range `[:,:, 7:21, 7:21]`.\n",
    "\n",
    "Visualization:\n",
    "- The code visualizes the original image, the flattened and reshaped image, and the center slice using Matplotlib's `imshow()` function.\n",
    "\n",
    "Converting between NumPy and PyTorch:\n",
    "- The code converts the PyTorch 'images' tensor to a NumPy array using the `cpu().numpy()` method.\n",
    "- It then converts the NumPy array back to a PyTorch tensor using `torch.from_numpy()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867bc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
